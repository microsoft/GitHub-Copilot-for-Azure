# Test all skills.
#
# Runs all integration tests.
# Triggered manually.

name: Integration Tests - all

permissions:
  id-token: write
  contents: read

on:
  workflow_dispatch:
    inputs:
      skills:
        description: 'Comma separated list of skills to test (e.g. "appinsights-instrumentation,azure-role-selector")'
        required: true
        type: string
      deploy-test-pattern:
        description: 'Optional: Comma separated patterns by name or describe block for filtering azure-deploy tests.'
        required: false
        type: string
        default: ''
      debug:
        description: 'Whether to set DEBUG=1 for jest tests'
        required: false
        type: boolean
        default: false

jobs:
  setup:
    name: Build skill matrix
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.set-matrix.outputs.matrix }}
      has_azure_deploy: ${{ steps.set-matrix.outputs.has_azure_deploy }}
    steps:
      - name: Parse skills input into matrix
        id: set-matrix
        run: |
          # Convert comma separated list of skills to a JSON array
          # Filter out azure-deploy (it runs via a separate reusable workflow)
          SKILLS="${{ inputs.skills }}"
          
          # Check if azure-deploy is in the list
          if echo "$SKILLS" | grep -q 'azure-deploy'; then
            echo "has_azure_deploy=true" >> "$GITHUB_OUTPUT"
          else
            echo "has_azure_deploy=false" >> "$GITHUB_OUTPUT"
          fi
          
          # Build matrix excluding azure-deploy
          JSON=$(echo "$SKILLS" | tr ',' '\n' | sed 's/^ *//;s/ *$//' | grep -v '^azure-deploy$' | jq -R . | jq -sc .)
          # Handle empty array case
          if [ "$JSON" = "[]" ]; then
            echo "matrix=[]" >> "$GITHUB_OUTPUT"
          else
            echo "matrix=$JSON" >> "$GITHUB_OUTPUT"
          fi

  # Call the azure-deploy workflow when azure-deploy is in the skills list
  azure-deploy:
    name: Integration – azure-deploy
    needs: setup
    if: needs.setup.outputs.has_azure_deploy == 'true'
    uses: ./.github/workflows/test-azure-deploy.yml
    with:
      test-pattern: ${{ inputs.deploy-test-pattern }}
      debug: ${{ inputs.debug }}
    secrets:
      COPILOT_CLI_TOKEN: ${{ secrets.COPILOT_CLI_TOKEN }}

  test:
    name: Integration – ${{ matrix.skill }}
    needs: setup
    if: needs.setup.outputs.matrix != '[]'
    environment: cideploytest
    runs-on: ubuntu-latest
    env:
      AZURE_CLIENT_ID: ${{ vars.AZURE_CLIENT_ID }}
      AZURE_TENANT_ID: ${{ vars.AZURE_TENANT_ID }}
      AZURE_SUBSCRIPTION_ID: ${{ vars.AZURE_SUBSCRIPTION_ID }}
    strategy:
      fail-fast: false            # don't cancel siblings on failure
      max-parallel: 5             # limit number of concurrent jobs
      matrix:
        skill: ${{ fromJson(needs.setup.outputs.matrix) }}

    defaults:
      run:
        working-directory: tests

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Install azd
        uses: Azure/setup-azd@v2

      - name: Log in with Azure (Federated Credentials)
        run: |
          azd auth login `
            --client-id "$Env:AZURE_CLIENT_ID" `
            --federated-credential-provider "github" `
            --tenant-id "$Env:AZURE_TENANT_ID"
        shell: pwsh

      - name: Azure login
        uses: azure/login@v2
        with:
          client-id: ${{ vars.AZURE_CLIENT_ID }}
          tenant-id: ${{ vars.AZURE_TENANT_ID }}
          subscription-id: ${{ vars.AZURE_SUBSCRIPTION_ID }}

      # azure/login only fetches the OIDC access token once.
      # If a test starts after the token expires, it will fail with authentication errors.
      # This step runs code to refresh the cached OIDC access token periodically to ensure all tests have a valid access token.
      # Learn more at https://github.com/Azure/login/issues/372
      - name: Fetch OIDC token every 300 seconds
        shell: bash
        env:
          AZURE_CLIENT_ID: ${{ vars.AZURE_CLIENT_ID }}
          AZURE_TENANT_ID: ${{ vars.AZURE_TENANT_ID }}
        run: |
          while true; do
            token=$(curl -s -H "Authorization: bearer ${ACTIONS_ID_TOKEN_REQUEST_TOKEN}" "${ACTIONS_ID_TOKEN_REQUEST_URL}&audience=api://AzureADTokenExchange" | jq .value -r)
            az login --service-principal -u $AZURE_CLIENT_ID -t $AZURE_TENANT_ID --federated-token $token --output none
            sleep 300
          done &

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '22'
          cache: 'npm'
          cache-dependency-path: tests/package-lock.json

      - name: Setup .NET
        if: contains(inputs.skills, 'azure-deploy')
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: '10.0.x'
      
      - name: Setup Python
        if: contains(inputs.skills, 'azure-deploy')
        uses: actions/setup-python@v5
        with:
          python-version: '3.13'

      - name: Install dependencies
        run: npm ci
      
      # COPILOT_CLI_TOKEN must be a fine-grained access token with the Account level Copilot Request permission
      # saved to the secrets of the microsoft/GitHub-Copilot-for-Azure repo.
      # As a known issue, when the permission of the token doesn't grant sufficient access,
      # the agent will hang instead of giving an error.
      # If you see the agent hang indefinitely, try refreshing the access token.
      # See https://github.com/github/copilot-sdk/issues/343 for more details.
      - name: Setup Copilot CLI
        id: setup-copilot-cli
        uses: mvkaran/setup-copilot-cli@v1
        with:
          token: ${{ secrets.COPILOT_CLI_TOKEN }}

      # Manually break down the integration tests per skill for easy tracking progress of a partially complete run.
      # Todo: Make test failure abort the workflow when we have baseline tests that must pass.
      # As of today, each step won't abort even if the integration test fails.
      # This is because many integration tests aren't polished enough and consistently fails.
      # Skill authors should use the reports to identify issues and polish their skills/tests.

      - name: Run integration tests – ${{ matrix.skill }}
        env:
          DEBUG: ${{ inputs.debug && '1' || '' }}
          TEST_RUN_ID: all-integration
        run: |
          # Handle azure-ai vs azure-aigateway prefix collision
          if [ "${{ matrix.skill }}" = "azure-ai" ]; then
            npm run test:integration azure-ai/
          else
            npm run test:integration ${{ matrix.skill }}
          fi
        continue-on-error: true
      
      - name: Generate skill report
        if: always()
        id: generate-skill-report
        run: npm run report -- --skill "${{ matrix.skill }}" || true

      - name: Show skill report
        if: always()
        id: show-skill-report
        run: |
          SKILL_REPORT=$(find reports -name "*-SKILL-REPORT.md" -type f | head -n 1)
          if [ -n "$SKILL_REPORT" ]; then
            echo "Found skill report: $SKILL_REPORT"
            cat "$SKILL_REPORT" >> "$GITHUB_STEP_SUMMARY"
          else
            echo "No skill report found"
          fi

      - name: Export report
        if: always()
        id: export-report
        uses: actions/upload-artifact@v4
        with:
          name: integration-report-${{ matrix.skill }}
          path: tests/reports/
          retention-days: 30

  report:
    name: Aggregate results
    needs: [test, azure-deploy]
    if: always()
    runs-on: ubuntu-latest
    steps:
      - name: Download all report artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: '{integration-report-*,azure-deploy-*-reports}'
          path: all-reports
          merge-multiple: true

      - name: Summarize
        run: |
          echo "## Integration Test Results" >> "$GITHUB_STEP_SUMMARY"
          for f in all-reports/*-SKILL-REPORT.md; do
            [ -f "$f" ] && cat "$f" >> "$GITHUB_STEP_SUMMARY" && echo "" >> "$GITHUB_STEP_SUMMARY"
          done
