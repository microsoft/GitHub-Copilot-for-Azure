# Skills Testing Guide

> **For AI Agents**: This document provides patterns and conventions for creating and maintaining tests for Azure Copilot skills. When asked to "scaffold tests" for a skill, follow the instructions below.

## Scaffolding Tests for a Skill

When a user asks to scaffold, create, or add tests for a skill, follow these steps:

### Step 1: Copy the template
```bash
cp -r tests/_template tests/{skill-name}
```

### Step 2: Read the skill's SKILL.md
Load the file at `plugin/skills/{skill-name}/SKILL.md` to understand:
- The skill's name and description (from frontmatter)
- What the skill does (from content)
- What Azure services/tools it references

### Step 3: Update test files
In each test file (`unit.test.js`, `triggers.test.js`, `integration.test.js`), change:
```javascript
const SKILL_NAME = '{skill-name}';  // Must match the folder name exactly
```

### Step 4: Generate trigger prompts
Based on the skill's description and content, add to `triggers.test.js`:

**shouldTriggerPrompts** (at least 5) - prompts that mention:
- The skill's primary Azure service (e.g., "Redis", "Cosmos DB", "Key Vault")
- Common tasks the skill helps with
- Keywords from the skill's description

**shouldNotTriggerPrompts** (at least 5) - prompts about:
- Unrelated topics ("weather", "poetry")
- Different cloud providers ("AWS", "GCP")
- Different Azure services not covered by this skill

### Step 5: Add skill-specific unit tests
In `unit.test.js`, add tests that verify the skill's content contains expected sections, commands, or patterns documented in its SKILL.md.

### Step 6: Add integration tests (if applicable)
If the skill mentions MCP tools (e.g., `azure__redis`, `azure__bicepschema`), add mocked integration tests.

### Step 7: Run and verify
```bash
cd tests
npm test -- --testPathPattern={skill-name}
```

### Step 8: Update coverage grid
```bash
npm run coverage:grid
```

---

## Overview

This testing framework uses **Jest** to validate skill behavior across three test categories:
- **Unit Tests** - Isolated logic testing
- **Trigger Tests** - Skill activation validation  
- **Integration Tests** - MCP tool interaction testing

## Quick Reference: Test File Conventions

---

## Test File Conventions

### File Naming

| File | Purpose |
|------|---------|
| `unit.test.js` | Tests isolated skill logic and metadata |
| `triggers.test.js` | Tests skill activation on prompts |
| `integration.test.js` | Tests MCP tool interactions |
| `fixtures/*.json` | Test data and mock responses |

### Directory Structure

```
tests/{skill-name}/
├── unit.test.js
├── triggers.test.js
├── integration.test.js
├── __snapshots__/        # Auto-generated by Jest
│   └── triggers.test.js.snap
└── fixtures/
    ├── prompts.json      # Trigger test prompts
    └── mcp-responses.json # Mock MCP responses
```

---

## Writing Unit Tests

Unit tests validate skill metadata and any extractable logic.

### Required Tests

Every skill should have these basic unit tests:

```javascript
describe('Skill Metadata', () => {
  test('has valid SKILL.md with required fields', () => {
    expect(skill.metadata.name).toBe(SKILL_NAME);
    expect(skill.metadata.description).toBeDefined();
    expect(skill.metadata.description.length).toBeGreaterThan(10);
  });
});
```

### Custom Logic Tests

If your skill has validation rules or processing logic, test them:

```javascript
describe('Naming Validation', () => {
  test('validates storage account names', () => {
    // 3-24 chars, lowercase + numbers only
    expect(isValidStorageName('validname123')).toBe(true);
    expect(isValidStorageName('INVALID-NAME')).toBe(false);
    expect(isValidStorageName('ab')).toBe(false);  // too short
  });
});
```

---

## Writing Trigger Tests

Trigger tests verify that prompts correctly activate (or don't activate) your skill.

### Parameterized Tests

Use `test.each` for testing multiple prompts:

```javascript
const shouldTriggerPrompts = [
  'How do I deploy to Azure App Service?',
  'Configure my Azure storage account',
  'Help with Azure CLI commands',
];

test.each(shouldTriggerPrompts)(
  'triggers on: "%s"',
  (prompt) => {
    const result = triggerMatcher.shouldTrigger(prompt);
    expect(result.triggered).toBe(true);
  }
);
```

### Snapshot Tests

Snapshots catch unintended changes to trigger behavior:

```javascript
test('skill keywords match snapshot', () => {
  expect(triggerMatcher.getKeywords()).toMatchSnapshot();
});
```

### Updating Snapshots

When trigger behavior intentionally changes:

```bash
npm run update:snapshots -- --testPathPattern=your-skill-name
```

**Always review snapshot changes before committing!**

---

## Writing Integration Tests

Integration tests validate MCP tool interactions using mocks.

### Mocking MCP Tools

```javascript
const { createMcpMock } = require('../utils/mcp-mock');

let mcpMock;

beforeEach(() => {
  mcpMock = createMcpMock();
});

test('calls bicep schema tool correctly', async () => {
  mcpMock.mockResponse('azure__bicepschema', {
    type: 'Microsoft.Storage/storageAccounts',
    properties: { name: { maxLength: 24 } }
  });

  // Your test logic
  const result = await yourFunction(mcpMock);
  
  // Verify mock was called
  expect(mcpMock.wasCalled('azure__bicepschema')).toBe(true);
});
```

### Testing Error Handling

```javascript
test('handles MCP errors gracefully', async () => {
  mcpMock.mockError('azure__bicepschema', new Error('Service unavailable'));

  // Should not throw, should handle gracefully
  await expect(yourFunction(mcpMock)).resolves.not.toThrow();
});
```

---

## Using Fixtures

### Loading Fixtures

```javascript
const { loadFixtures, loadFixture } = require('../utils/fixtures');

// Load all fixtures for a skill
const fixtures = loadFixtures('azure-validation');

// Load a specific fixture
const prompts = loadFixture('azure-validation', 'prompts');
```

### Fixture File Format

`fixtures/prompts.json`:
```json
{
  "shouldTrigger": [
    "Deploy to Azure",
    "Configure storage account"
  ],
  "shouldNotTrigger": [
    "Help with AWS",
    "Write a poem"
  ]
}
```

---

## Running Tests

### Local Development

```bash
# All tests
npm test

# Specific skill
npm test -- --testPathPattern=azure-validation

# Watch mode
npm run test:watch -- --testPathPattern=azure-validation

# With coverage
npm run test:coverage -- --testPathPattern=azure-validation

# Verbose output
npm run test:verbose
```

### CI Environment

Tests automatically run on:
- Push to `main` affecting skill or test files
- Pull requests affecting skill or test files
- Manual workflow dispatch

Output formats:
- **Console**: Human-readable Jest output
- **CI**: JUnit XML in `tests/reports/junit.xml`
- **PR**: Annotations via GitHub Actions

---

## Coverage Requirements

### Minimum Thresholds

| Metric | Target |
|--------|--------|
| Statements | 60% |
| Branches | 50% |
| Functions | 60% |
| Lines | 60% |

### Checking Coverage

```bash
npm run test:coverage
```

Coverage reports are generated in `tests/coverage/`.

---

## GitHub Actions Integration

### Per-Skill Workflows

Generate workflow for a new skill:

```bash
node scripts/generate-skill-workflows.js
```

This creates `.github/workflows/test-skill-{name}.yml` that triggers on:
- Changes to `plugin/skills/{name}/**`
- Changes to `tests/{name}/**`
- Manual dispatch

### Full Test Suite

`.github/workflows/test-all-skills.yml` runs all skill tests and updates the README coverage grid.

---

## Troubleshooting

### Test Not Running

1. Check skill name matches folder name exactly
2. Verify test file ends with `.test.js`
3. Check `testPathIgnorePatterns` in `jest.config.js`

### Snapshot Mismatch

1. Review the diff carefully
2. If change is intentional: `npm run update:snapshots`
3. If change is unintentional: investigate and fix

### MCP Mock Not Working

1. Verify tool name matches exactly (e.g., `azure__bicepschema`)
2. Call `mcpMock.reset()` in `afterEach`
3. Check mock was set up before test logic runs

---

## Best Practices

1. **One assertion per test** when possible for clear failure messages
2. **Descriptive test names**: `test('rejects storage names over 24 characters')`
3. **Test edge cases**: Empty input, very long input, special characters
4. **Keep fixtures small**: Only include data needed for the test
5. **Review snapshots**: Don't blindly update—understand the change
6. **Clean up mocks**: Reset between tests to prevent interference

---

## Adding Tests Checklist

When adding tests for a new skill:

- [ ] Copy `_template/` to `tests/{skill-name}/`
- [ ] Update `SKILL_NAME` in all test files
- [ ] Add 5+ prompts that should trigger
- [ ] Add 5+ prompts that should NOT trigger  
- [ ] Add unit tests for any validation logic
- [ ] Add integration tests if skill uses MCP tools
- [ ] Run tests locally and verify passing
- [ ] Generate per-skill workflow (optional)
- [ ] Update coverage grid if significant changes

---

*Last updated: Auto-generated by skill testing framework*
